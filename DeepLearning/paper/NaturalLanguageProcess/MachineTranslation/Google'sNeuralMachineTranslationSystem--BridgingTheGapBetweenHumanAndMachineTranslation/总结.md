3、模型并行化

（1）数据并行：同时训练n个模型的副本，在n个副本之间进行参数共享，每个副本对参数进行异步更新；

（2）模型并行：将网络的不同层跑在不同的gpu上；对softmax层也进行分解，使不同的子集跑在不同的gpu上；

（3）限制：模型并行化对模型架构带来了一些限制，例如：不能在所有的encoder层使用双向网络；不能用decoder的顶层输出进行attention计算，只能用最底层。



三、分段方法：在对oov的词进行翻译时，通常有两种方法，一是copy，基于外部对齐模型的attention，或者负载的特定目标的指向网络；二是子词单元（sub-word units），使用字符、混合词/字符，或者其他子词。

1、本文中最成功的方法是使用子词单元，以数据驱动的方式建立子词模型

2、针对在翻译中需要把某些稀有词直接从输入copy到输出的情况，本文中在源语言和目标语言上使用共享的子词模型来解决。保证了在源语言和目标语言中，相同的字符串以相同的方式被分段，更容易进行copy。

3、子词模型（wordpiece）在字符模型的灵活性和单词模型的有效性之间取得了一个折衷，能够更有效的处理“无限字典”的问题。

4、另外一个解决oov问题的办法是使用混合单词/字符模型：首先像传统模型一样维护一个词典，然后在碰到oov词的时候，将其分解成对应的字符进行处理。